{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comfortable-soldier",
   "metadata": {},
   "source": [
    "1. Cross Validation done wrong.\n",
    "\n",
    "* Pick 50 training points uniformly at random from a space of 1,000 predictors, each with values between -1 and 1.\n",
    "* Assign a class of 0 or 1 at random to each training point.\n",
    "* Choose the 50 predictors with highest correlation (positive or negative) to the class labels.\n",
    "* Use those 50 predictors to fit a multivariate logistic model to the data, using 5-fold CV.\n",
    "* What is the estimated test error? What will the actual test error be?\n",
    "* Discuss what's wrong and how to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "equipped-browser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.366748</td>\n",
       "      <td>0.100619</td>\n",
       "      <td>-0.892637</td>\n",
       "      <td>0.301010</td>\n",
       "      <td>-0.666246</td>\n",
       "      <td>-0.330541</td>\n",
       "      <td>-0.703674</td>\n",
       "      <td>-0.621062</td>\n",
       "      <td>0.695167</td>\n",
       "      <td>-0.918674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266348</td>\n",
       "      <td>0.122490</td>\n",
       "      <td>0.923214</td>\n",
       "      <td>0.106023</td>\n",
       "      <td>-0.343050</td>\n",
       "      <td>-0.140817</td>\n",
       "      <td>0.367668</td>\n",
       "      <td>0.687890</td>\n",
       "      <td>-0.899859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329519</td>\n",
       "      <td>-0.776190</td>\n",
       "      <td>-0.076880</td>\n",
       "      <td>-0.229845</td>\n",
       "      <td>-0.739654</td>\n",
       "      <td>0.968763</td>\n",
       "      <td>0.364334</td>\n",
       "      <td>0.873849</td>\n",
       "      <td>-0.833543</td>\n",
       "      <td>-0.521601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065884</td>\n",
       "      <td>-0.845229</td>\n",
       "      <td>0.638266</td>\n",
       "      <td>0.760926</td>\n",
       "      <td>0.454736</td>\n",
       "      <td>0.992653</td>\n",
       "      <td>-0.939394</td>\n",
       "      <td>0.075003</td>\n",
       "      <td>0.776047</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.951588</td>\n",
       "      <td>0.017340</td>\n",
       "      <td>0.424118</td>\n",
       "      <td>-0.642542</td>\n",
       "      <td>0.572098</td>\n",
       "      <td>0.925933</td>\n",
       "      <td>-0.479382</td>\n",
       "      <td>0.870330</td>\n",
       "      <td>0.650130</td>\n",
       "      <td>0.247728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117771</td>\n",
       "      <td>-0.936692</td>\n",
       "      <td>-0.973621</td>\n",
       "      <td>0.649528</td>\n",
       "      <td>0.221880</td>\n",
       "      <td>-0.565495</td>\n",
       "      <td>-0.558369</td>\n",
       "      <td>0.103778</td>\n",
       "      <td>-0.352521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.502654</td>\n",
       "      <td>-0.490307</td>\n",
       "      <td>0.795844</td>\n",
       "      <td>-0.990226</td>\n",
       "      <td>-0.258012</td>\n",
       "      <td>0.053198</td>\n",
       "      <td>-0.077363</td>\n",
       "      <td>-0.858374</td>\n",
       "      <td>-0.540148</td>\n",
       "      <td>-0.807974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324635</td>\n",
       "      <td>-0.991101</td>\n",
       "      <td>-0.258208</td>\n",
       "      <td>0.078209</td>\n",
       "      <td>-0.067141</td>\n",
       "      <td>-0.730180</td>\n",
       "      <td>0.629627</td>\n",
       "      <td>-0.163791</td>\n",
       "      <td>0.621326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.749013</td>\n",
       "      <td>-0.304119</td>\n",
       "      <td>0.770020</td>\n",
       "      <td>-0.045364</td>\n",
       "      <td>-0.123389</td>\n",
       "      <td>0.902632</td>\n",
       "      <td>-0.438046</td>\n",
       "      <td>0.148432</td>\n",
       "      <td>0.857715</td>\n",
       "      <td>-0.652853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228829</td>\n",
       "      <td>-0.704730</td>\n",
       "      <td>-0.966439</td>\n",
       "      <td>0.425631</td>\n",
       "      <td>-0.736355</td>\n",
       "      <td>-0.620565</td>\n",
       "      <td>0.967580</td>\n",
       "      <td>0.294766</td>\n",
       "      <td>0.397679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.366748  0.100619 -0.892637  0.301010 -0.666246 -0.330541 -0.703674   \n",
       "1  0.329519 -0.776190 -0.076880 -0.229845 -0.739654  0.968763  0.364334   \n",
       "2 -0.951588  0.017340  0.424118 -0.642542  0.572098  0.925933 -0.479382   \n",
       "3 -0.502654 -0.490307  0.795844 -0.990226 -0.258012  0.053198 -0.077363   \n",
       "4  0.749013 -0.304119  0.770020 -0.045364 -0.123389  0.902632 -0.438046   \n",
       "\n",
       "          7         8         9  ...       991       992       993       994  \\\n",
       "0 -0.621062  0.695167 -0.918674  ...  0.266348  0.122490  0.923214  0.106023   \n",
       "1  0.873849 -0.833543 -0.521601  ... -0.065884 -0.845229  0.638266  0.760926   \n",
       "2  0.870330  0.650130  0.247728  ...  0.117771 -0.936692 -0.973621  0.649528   \n",
       "3 -0.858374 -0.540148 -0.807974  ...  0.324635 -0.991101 -0.258208  0.078209   \n",
       "4  0.148432  0.857715 -0.652853  ...  0.228829 -0.704730 -0.966439  0.425631   \n",
       "\n",
       "        995       996       997       998       999  y  \n",
       "0 -0.343050 -0.140817  0.367668  0.687890 -0.899859  1  \n",
       "1  0.454736  0.992653 -0.939394  0.075003  0.776047  1  \n",
       "2  0.221880 -0.565495 -0.558369  0.103778 -0.352521  0  \n",
       "3 -0.067141 -0.730180  0.629627 -0.163791  0.621326  0  \n",
       "4 -0.736355 -0.620565  0.967580  0.294766  0.397679  1  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "foo = [0, 1]\n",
    "for i in range(50):\n",
    "    point = np.random.uniform(-1,1,1000)\n",
    "    assigned_class = random.choice(foo)\n",
    "    x.append(point)\n",
    "    y.append(assigned_class)\n",
    "    \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "df = pd.DataFrame(data=x)\n",
    "df['y'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "explicit-cartridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020460</td>\n",
       "      <td>0.155740</td>\n",
       "      <td>-0.018084</td>\n",
       "      <td>-0.135355</td>\n",
       "      <td>-0.148893</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>-0.033765</td>\n",
       "      <td>-0.038753</td>\n",
       "      <td>0.159953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058934</td>\n",
       "      <td>-0.143293</td>\n",
       "      <td>-0.054432</td>\n",
       "      <td>-0.151875</td>\n",
       "      <td>-0.028303</td>\n",
       "      <td>0.372704</td>\n",
       "      <td>-0.012408</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>-0.048608</td>\n",
       "      <td>0.149678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.020460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.211148</td>\n",
       "      <td>-0.015651</td>\n",
       "      <td>0.219418</td>\n",
       "      <td>-0.238953</td>\n",
       "      <td>0.100785</td>\n",
       "      <td>-0.055679</td>\n",
       "      <td>0.246766</td>\n",
       "      <td>0.035979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116114</td>\n",
       "      <td>-0.053988</td>\n",
       "      <td>-0.092456</td>\n",
       "      <td>0.104096</td>\n",
       "      <td>0.055546</td>\n",
       "      <td>-0.047207</td>\n",
       "      <td>0.113093</td>\n",
       "      <td>-0.081298</td>\n",
       "      <td>-0.108193</td>\n",
       "      <td>0.243637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155740</td>\n",
       "      <td>-0.211148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018122</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>0.206801</td>\n",
       "      <td>-0.168569</td>\n",
       "      <td>0.245777</td>\n",
       "      <td>0.055606</td>\n",
       "      <td>0.303956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179427</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>-0.189336</td>\n",
       "      <td>0.228890</td>\n",
       "      <td>-0.109844</td>\n",
       "      <td>-0.074214</td>\n",
       "      <td>-0.053630</td>\n",
       "      <td>0.056788</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>-0.376864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.018084</td>\n",
       "      <td>-0.015651</td>\n",
       "      <td>-0.018122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.179709</td>\n",
       "      <td>-0.127704</td>\n",
       "      <td>-0.185776</td>\n",
       "      <td>-0.135978</td>\n",
       "      <td>0.060688</td>\n",
       "      <td>-0.148419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168716</td>\n",
       "      <td>-0.051321</td>\n",
       "      <td>-0.061294</td>\n",
       "      <td>-0.074025</td>\n",
       "      <td>0.088340</td>\n",
       "      <td>-0.289476</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>-0.305258</td>\n",
       "      <td>-0.219297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.135355</td>\n",
       "      <td>0.219418</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>-0.179709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.178157</td>\n",
       "      <td>0.061234</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.165197</td>\n",
       "      <td>0.197485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016145</td>\n",
       "      <td>0.043896</td>\n",
       "      <td>0.125817</td>\n",
       "      <td>0.091586</td>\n",
       "      <td>0.124123</td>\n",
       "      <td>-0.094734</td>\n",
       "      <td>-0.022392</td>\n",
       "      <td>-0.462359</td>\n",
       "      <td>0.081245</td>\n",
       "      <td>-0.054584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.372704</td>\n",
       "      <td>-0.047207</td>\n",
       "      <td>-0.074214</td>\n",
       "      <td>-0.289476</td>\n",
       "      <td>-0.094734</td>\n",
       "      <td>-0.004876</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>-0.009476</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.161037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253809</td>\n",
       "      <td>0.053549</td>\n",
       "      <td>0.131039</td>\n",
       "      <td>-0.068679</td>\n",
       "      <td>-0.097100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.319491</td>\n",
       "      <td>0.057724</td>\n",
       "      <td>0.129288</td>\n",
       "      <td>0.385213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.012408</td>\n",
       "      <td>0.113093</td>\n",
       "      <td>-0.053630</td>\n",
       "      <td>0.086603</td>\n",
       "      <td>-0.022392</td>\n",
       "      <td>-0.230056</td>\n",
       "      <td>-0.106501</td>\n",
       "      <td>-0.303559</td>\n",
       "      <td>-0.055930</td>\n",
       "      <td>-0.004781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101404</td>\n",
       "      <td>0.097194</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>-0.177833</td>\n",
       "      <td>-0.326468</td>\n",
       "      <td>-0.319491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100058</td>\n",
       "      <td>-0.082855</td>\n",
       "      <td>-0.009175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.007241</td>\n",
       "      <td>-0.081298</td>\n",
       "      <td>0.056788</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>-0.462359</td>\n",
       "      <td>0.216927</td>\n",
       "      <td>-0.218460</td>\n",
       "      <td>0.252561</td>\n",
       "      <td>0.099795</td>\n",
       "      <td>-0.119833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049204</td>\n",
       "      <td>0.032255</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>-0.239323</td>\n",
       "      <td>-0.145237</td>\n",
       "      <td>0.057724</td>\n",
       "      <td>0.100058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>0.075434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.048608</td>\n",
       "      <td>-0.108193</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>-0.305258</td>\n",
       "      <td>0.081245</td>\n",
       "      <td>0.055183</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>-0.208208</td>\n",
       "      <td>-0.018085</td>\n",
       "      <td>-0.015733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054432</td>\n",
       "      <td>0.074435</td>\n",
       "      <td>0.051886</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>-0.034196</td>\n",
       "      <td>0.129288</td>\n",
       "      <td>-0.082855</td>\n",
       "      <td>0.006751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.149678</td>\n",
       "      <td>0.243637</td>\n",
       "      <td>-0.376864</td>\n",
       "      <td>-0.219297</td>\n",
       "      <td>-0.054584</td>\n",
       "      <td>-0.064202</td>\n",
       "      <td>-0.005054</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>-0.042391</td>\n",
       "      <td>0.125602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063693</td>\n",
       "      <td>0.101993</td>\n",
       "      <td>0.194656</td>\n",
       "      <td>-0.140571</td>\n",
       "      <td>-0.050882</td>\n",
       "      <td>0.385213</td>\n",
       "      <td>-0.009175</td>\n",
       "      <td>0.075434</td>\n",
       "      <td>0.241839</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.000000 -0.020460  0.155740 -0.018084 -0.135355 -0.148893  0.032955   \n",
       "1   -0.020460  1.000000 -0.211148 -0.015651  0.219418 -0.238953  0.100785   \n",
       "2    0.155740 -0.211148  1.000000 -0.018122  0.012610  0.206801 -0.168569   \n",
       "3   -0.018084 -0.015651 -0.018122  1.000000 -0.179709 -0.127704 -0.185776   \n",
       "4   -0.135355  0.219418  0.012610 -0.179709  1.000000 -0.178157  0.061234   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "996  0.372704 -0.047207 -0.074214 -0.289476 -0.094734 -0.004876  0.235107   \n",
       "997 -0.012408  0.113093 -0.053630  0.086603 -0.022392 -0.230056 -0.106501   \n",
       "998  0.007241 -0.081298  0.056788  0.038388 -0.462359  0.216927 -0.218460   \n",
       "999 -0.048608 -0.108193  0.013861 -0.305258  0.081245  0.055183  0.018516   \n",
       "y    0.149678  0.243637 -0.376864 -0.219297 -0.054584 -0.064202 -0.005054   \n",
       "\n",
       "            7         8         9  ...       991       992       993  \\\n",
       "0   -0.033765 -0.038753  0.159953  ...  0.058934 -0.143293 -0.054432   \n",
       "1   -0.055679  0.246766  0.035979  ... -0.116114 -0.053988 -0.092456   \n",
       "2    0.245777  0.055606  0.303956  ... -0.179427  0.016248 -0.189336   \n",
       "3   -0.135978  0.060688 -0.148419  ... -0.168716 -0.051321 -0.061294   \n",
       "4    0.014187  0.165197  0.197485  ... -0.016145  0.043896  0.125817   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "996 -0.009476  0.051937  0.161037  ...  0.253809  0.053549  0.131039   \n",
       "997 -0.303559 -0.055930 -0.004781  ...  0.101404  0.097194  0.014710   \n",
       "998  0.252561  0.099795 -0.119833  ... -0.049204  0.032255 -0.004667   \n",
       "999 -0.208208 -0.018085 -0.015733  ...  0.054432  0.074435  0.051886   \n",
       "y    0.036825 -0.042391  0.125602  ... -0.063693  0.101993  0.194656   \n",
       "\n",
       "          994       995       996       997       998       999         y  \n",
       "0   -0.151875 -0.028303  0.372704 -0.012408  0.007241 -0.048608  0.149678  \n",
       "1    0.104096  0.055546 -0.047207  0.113093 -0.081298 -0.108193  0.243637  \n",
       "2    0.228890 -0.109844 -0.074214 -0.053630  0.056788  0.013861 -0.376864  \n",
       "3   -0.074025  0.088340 -0.289476  0.086603  0.038388 -0.305258 -0.219297  \n",
       "4    0.091586  0.124123 -0.094734 -0.022392 -0.462359  0.081245 -0.054584  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "996 -0.068679 -0.097100  1.000000 -0.319491  0.057724  0.129288  0.385213  \n",
       "997 -0.177833 -0.326468 -0.319491  1.000000  0.100058 -0.082855 -0.009175  \n",
       "998 -0.239323 -0.145237  0.057724  0.100058  1.000000  0.006751  0.075434  \n",
       "999  0.001353 -0.034196  0.129288 -0.082855  0.006751  1.000000  0.241839  \n",
       "y   -0.140571 -0.050882  0.385213 -0.009175  0.075434  0.241839  1.000000  \n",
       "\n",
       "[1001 rows x 1001 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "played-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['y', 782, 380, 103,  10, 996, 298, 653, 691,   2, 935, 905, 135, 348,\n",
      "       731, 432, 343, 436, 201, 865, 471, 590, 692, 519, 315, 415, 749, 846,\n",
      "       970, 223, 185,  42, 887, 596, 565, 672, 948, 810, 339, 224, 675, 289,\n",
      "       614, 832, 259, 497, 107, 133, 816, 857, 229],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y      1.000000\n",
       "782    0.434091\n",
       "380    0.415356\n",
       "103    0.390153\n",
       "10     0.388762\n",
       "996    0.385213\n",
       "298    0.382790\n",
       "653    0.379720\n",
       "691    0.378186\n",
       "2      0.376864\n",
       "935    0.375540\n",
       "905    0.364372\n",
       "135    0.360322\n",
       "348    0.358375\n",
       "731    0.354681\n",
       "432    0.352047\n",
       "343    0.338360\n",
       "436    0.334976\n",
       "201    0.334623\n",
       "865    0.324990\n",
       "471    0.319905\n",
       "590    0.319374\n",
       "692    0.318372\n",
       "519    0.315229\n",
       "315    0.313512\n",
       "415    0.310700\n",
       "749    0.310449\n",
       "846    0.309849\n",
       "970    0.305298\n",
       "223    0.304695\n",
       "185    0.304364\n",
       "42     0.301683\n",
       "887    0.299125\n",
       "596    0.298889\n",
       "565    0.297942\n",
       "672    0.294938\n",
       "948    0.294823\n",
       "810    0.293833\n",
       "339    0.293761\n",
       "224    0.293729\n",
       "675    0.293053\n",
       "289    0.290030\n",
       "614    0.289365\n",
       "832    0.288874\n",
       "259    0.287672\n",
       "497    0.287554\n",
       "107    0.287196\n",
       "133    0.286540\n",
       "816    0.286269\n",
       "857    0.286015\n",
       "229    0.285611\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_corr = df.corr().abs()['y']\n",
    "print(type(y_corr))\n",
    "\n",
    "print(y_corr.nlargest(51).index)\n",
    "y_corr.nlargest(51)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "altered-willow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>917</th>\n",
       "      <th>288</th>\n",
       "      <th>305</th>\n",
       "      <th>4</th>\n",
       "      <th>48</th>\n",
       "      <th>164</th>\n",
       "      <th>946</th>\n",
       "      <th>15</th>\n",
       "      <th>421</th>\n",
       "      <th>...</th>\n",
       "      <th>895</th>\n",
       "      <th>210</th>\n",
       "      <th>898</th>\n",
       "      <th>130</th>\n",
       "      <th>406</th>\n",
       "      <th>433</th>\n",
       "      <th>456</th>\n",
       "      <th>330</th>\n",
       "      <th>96</th>\n",
       "      <th>658</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.528906</td>\n",
       "      <td>-0.410804</td>\n",
       "      <td>-0.188382</td>\n",
       "      <td>-0.666246</td>\n",
       "      <td>-0.867426</td>\n",
       "      <td>-0.448797</td>\n",
       "      <td>-0.213241</td>\n",
       "      <td>0.210711</td>\n",
       "      <td>0.441538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.764903</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>-0.271115</td>\n",
       "      <td>0.297168</td>\n",
       "      <td>0.603922</td>\n",
       "      <td>-0.563026</td>\n",
       "      <td>0.094350</td>\n",
       "      <td>0.950587</td>\n",
       "      <td>-0.351079</td>\n",
       "      <td>0.497688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987224</td>\n",
       "      <td>-0.726957</td>\n",
       "      <td>-0.062300</td>\n",
       "      <td>-0.739654</td>\n",
       "      <td>-0.378385</td>\n",
       "      <td>0.349080</td>\n",
       "      <td>0.825335</td>\n",
       "      <td>0.093671</td>\n",
       "      <td>-0.766708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907211</td>\n",
       "      <td>0.322687</td>\n",
       "      <td>0.740008</td>\n",
       "      <td>0.433573</td>\n",
       "      <td>-0.003886</td>\n",
       "      <td>-0.938078</td>\n",
       "      <td>-0.071482</td>\n",
       "      <td>-0.083702</td>\n",
       "      <td>0.072689</td>\n",
       "      <td>-0.376772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.808545</td>\n",
       "      <td>-0.097781</td>\n",
       "      <td>0.785170</td>\n",
       "      <td>0.572098</td>\n",
       "      <td>0.149649</td>\n",
       "      <td>-0.243643</td>\n",
       "      <td>0.118952</td>\n",
       "      <td>-0.585057</td>\n",
       "      <td>0.880953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253652</td>\n",
       "      <td>-0.038946</td>\n",
       "      <td>0.190514</td>\n",
       "      <td>0.684397</td>\n",
       "      <td>-0.224684</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>-0.869607</td>\n",
       "      <td>-0.953022</td>\n",
       "      <td>-0.180143</td>\n",
       "      <td>0.034739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.127005</td>\n",
       "      <td>0.483621</td>\n",
       "      <td>-0.757423</td>\n",
       "      <td>-0.258012</td>\n",
       "      <td>0.983391</td>\n",
       "      <td>-0.916171</td>\n",
       "      <td>0.259835</td>\n",
       "      <td>0.850247</td>\n",
       "      <td>-0.236623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477956</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.988494</td>\n",
       "      <td>-0.723611</td>\n",
       "      <td>-0.520876</td>\n",
       "      <td>0.491451</td>\n",
       "      <td>0.826278</td>\n",
       "      <td>0.887778</td>\n",
       "      <td>0.793532</td>\n",
       "      <td>-0.340191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.895758</td>\n",
       "      <td>0.236339</td>\n",
       "      <td>0.472089</td>\n",
       "      <td>-0.123389</td>\n",
       "      <td>0.875531</td>\n",
       "      <td>0.474046</td>\n",
       "      <td>-0.791924</td>\n",
       "      <td>-0.285321</td>\n",
       "      <td>0.777368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.566466</td>\n",
       "      <td>-0.850353</td>\n",
       "      <td>-0.818247</td>\n",
       "      <td>0.441961</td>\n",
       "      <td>0.591323</td>\n",
       "      <td>0.084807</td>\n",
       "      <td>-0.540921</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>-0.469095</td>\n",
       "      <td>-0.933811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y       917       288       305         4        48       164       946  \\\n",
       "0  1 -0.528906 -0.410804 -0.188382 -0.666246 -0.867426 -0.448797 -0.213241   \n",
       "1  1 -0.987224 -0.726957 -0.062300 -0.739654 -0.378385  0.349080  0.825335   \n",
       "2  0  0.808545 -0.097781  0.785170  0.572098  0.149649 -0.243643  0.118952   \n",
       "3  0 -0.127005  0.483621 -0.757423 -0.258012  0.983391 -0.916171  0.259835   \n",
       "4  1 -0.895758  0.236339  0.472089 -0.123389  0.875531  0.474046 -0.791924   \n",
       "\n",
       "         15       421  ...       895       210       898       130       406  \\\n",
       "0  0.210711  0.441538  ... -0.764903  0.870208 -0.271115  0.297168  0.603922   \n",
       "1  0.093671 -0.766708  ... -0.907211  0.322687  0.740008  0.433573 -0.003886   \n",
       "2 -0.585057  0.880953  ...  0.253652 -0.038946  0.190514  0.684397 -0.224684   \n",
       "3  0.850247 -0.236623  ... -0.477956  0.001982  0.988494 -0.723611 -0.520876   \n",
       "4 -0.285321  0.777368  ... -0.566466 -0.850353 -0.818247  0.441961  0.591323   \n",
       "\n",
       "        433       456       330        96       658  \n",
       "0 -0.563026  0.094350  0.950587 -0.351079  0.497688  \n",
       "1 -0.938078 -0.071482 -0.083702  0.072689 -0.376772  \n",
       "2  0.021527 -0.869607 -0.953022 -0.180143  0.034739  \n",
       "3  0.491451  0.826278  0.887778  0.793532 -0.340191  \n",
       "4  0.084807 -0.540921  0.027665 -0.469095 -0.933811  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model as skl_lm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#formula = 'y ~ Q(\"917\")+288+305+4+48+164+946+15+421+996+950+309+641+687+531+810+552+163+949+788+523+412+994+845+751+455+872+1+80+756+253+777+991+693+293+467+14+266+880+530+895+210+898+130+406+433+456+330+96+658\")'\n",
    "formula = 'y ~ Q(\"917\") + Q(\"305\")'\n",
    "df2 = df.filter(['y', 917, 288, 305,   4,  48, 164, 946,  15, 421, 996, 950, 309, 641,\n",
    "       687, 531, 810, 552, 163, 949, 788, 523, 412, 994, 845, 751, 455, 872,\n",
    "         1,  80, 756, 253, 777, 991, 693, 293, 467,  14, 266, 880, 530, 895,\n",
    "       210, 898, 130, 406, 433, 456, 330,  96, 658], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "tracked-grade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores\n",
      "[0.5 0.7 0.7 0.6 0.8]\n",
      "Accuracy: 0.660 (0.102)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate a logistic regression model using k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df2.iloc[:,[1,50]]\n",
    "y = df2['y']\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Evaluating accuracy\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print(\"scores\")\n",
    "print(scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-burns",
   "metadata": {},
   "source": [
    "## What is the estimated test error? What will the actual test error be?\n",
    "\n",
    "* Accuracy: Overall, how often is the classifier correct? (TP + TN)/total\n",
    "* In the first iteration, the accuracy is 60%\n",
    "* Second iteration, the accuracy is 70% and so on\n",
    "\n",
    "## Discuss what's wrong and how to fix it.\n",
    "* what is wrong is that we picked the most 50 correlated predictors before dividing the data into folds. To correct it, we should pick the correlated pridctors after separating one part of the data as a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-identification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amino-johns",
   "metadata": {},
   "source": [
    "2. LOOCV. This problem is modeled on chapter 5, problem 8, but instead of LaTeX: y = x - 2x^2 + \\epsilony = x − 2 x 2 + ϵ \n",
    "* I will ask you to use the function and models from the Week 02 assignment. \n",
    "* You may start with your solution or start with my solution instead.\n",
    "\n",
    "* Modify the Week 02 assignment notebook to generate just two training set of 15 points each instead of 10 training sets.\n",
    "* Create a scatterplot of Y versus X. for each training set. Comment on what you find.\n",
    "--------\n",
    "* Fit each of the five polynomial models from the Week 02 assignment to both training sets. Compute the LOOCV estimate of test error each time. That's 10 estimates.\n",
    "* Compare the five estimates from the first training set to the five estimates from the second training set and comment on what you see.\n",
    "* Compare the five models. Which had the smallest LOOCV estimate for the first training set? For the second training set? Is this what you expected? Explain.\n",
    "* Print a summary of each model fit. Consider the statistical significance of each variable in each model fit. Do these reported statistical significances agree with the conclusions you drew from the LOOCV estimates in part E?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "practical-masters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15) (2, 15)\n"
     ]
    }
   ],
   "source": [
    "x1train = np.random.uniform(0, 5, (2, 15))\n",
    "ytrain = (x1train**3 - 5*x1train**2 + x1train + 2 + np.random.normal(0, 2, (2, 15)))\n",
    "print(x1train.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "contained-protein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x1train, ytrain, 'o', color='black');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-edgar",
   "metadata": {},
   "source": [
    "### Comment on what you find\n",
    "The data made a parabola with a big minima around x=3 ands a small one on the top left I think?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "funny-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import sklearn.linear_model as skl_lm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "lm = skl_lm.LinearRegression()\n",
    "x1 = x1train[0].reshape(-1,1)\n",
    "x2 = x1train[1].reshape(-1,1)\n",
    "y1 = ytrain[0].reshape(-1,1)\n",
    "y2 = ytrain[1].reshape(-1,1)\n",
    "x_all = numpy.append(x1, x2).reshape(-1,1)\n",
    "y_all = numpy.append(y1, y2).reshape(-1,1)\n",
    "\n",
    "model = lm.fit(x_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "defined-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree-1 polynomial MSE: 44.11490924516916, STD: 52.90002044326817\n",
      "Degree-2 polynomial MSE: 2.82958936362253, STD: 4.174417730481867\n",
      "Degree-3 polynomial MSE: 3.2061941038269923, STD: 4.379930506234112\n",
      "Degree-4 polynomial MSE: 4.096182840937447, STD: 5.229625200021677\n",
      "Degree-5 polynomial MSE: 6.417924505481303, STD: 7.975795879401264\n"
     ]
    }
   ],
   "source": [
    "x = x1\n",
    "y = y1\n",
    "\n",
    "for i in range(1,6):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_current = poly.fit_transform(x)\n",
    "    model1 = lm.fit(X_current, y)\n",
    "    scores = cross_val_score(model1, X_current, y, scoring=\"neg_mean_squared_error\", cv=crossvalidation,\n",
    " n_jobs=1)\n",
    "    \n",
    "    print(\"Degree-\"+str(i)+\" polynomial MSE: \" + str(np.mean(np.abs(scores))) + \", STD: \" + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-zimbabwe",
   "metadata": {},
   "source": [
    "x = x2\n",
    "y = y2\n",
    "\n",
    "for i in range(1,6):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X_current = poly.fit_transform(x)\n",
    "    model2 = lm.fit(X_current, y)\n",
    "    scores = cross_val_score(model2, X_current, y, scoring=\"neg_mean_squared_error\", cv=crossvalidation,\n",
    " n_jobs=1)\n",
    "    \n",
    "    print(\"Degree-\"+str(i)+\" polynomial MSE: \" + str(np.mean(np.abs(scores))) + \", STD: \" + str(np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-heather",
   "metadata": {},
   "source": [
    "### Compare the five models\n",
    "\n",
    "* The MSE estimate of the degree 1 polynomial in both training sets is the hegihst or worst. This is probably because the model is too simple and didn't capture enough details about the data.\n",
    "\n",
    "* The estimate values (3, 4, 6) were repeated in both of them. The difference between those values is very small, +/- 1 or 2. Even though it was repeated for different degrees, for example:\n",
    "  - 1] In the first data set degree 3 had MSE of 3 and degree 4 had MSE 0f 4\n",
    "  - 2] In the second data set degree 3 had MSE of 4 and degree 4 had MSE 0f 3\n",
    "  - 3] This lead me to think that those models are probably the same in terms of which is better. It might have been that degree 4 is the same as degree 3 but with a zero estimate for the x^4 predictor?!\n",
    "  - 4] Also since the different between the last four models is very small, I assumed that what I mentioned in point 3] applies to them too in general\n",
    "\n",
    "### . Which had the smallest LOOCV estimate for the first training set? For the second training set? Is this what you expected? Explain.\n",
    "\n",
    "* For the first training set, Degree 2 had the smallest estimate of MSE = 2.8\n",
    "* For the second training set, Degree 4 had the smallest estimate of MSE = 3.4\n",
    "* I expected the least MSE will be eaither degree 2 or 3 just because in the original plot of the two data sets, there is a global minima around x=3 and another very small curve around x=0.5. \n",
    "* Sometimes I don't get that small curve when I plot different data sets, so this is why I said either degree 2 or 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "spoken-costs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== SUMMARY ===========\n",
      "(50, 1000)\n",
      "(50,)\n",
      "(1,)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dimension of xlabels (1,) does not match X (50, 1000).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-e9331066ccca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# I don't know why it doesn't like my \"xlabels\" 😔?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/regressors/stats.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(clf, X, y, xlabels)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;31m# Make sure dims of xlabels matches dims of X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         raise AssertionError(\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0;34m\"Dimension of xlabels {0} does not match \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \"X {1}.\".format(xlabels.shape, X.shape))\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dimension of xlabels (1,) does not match X (50, 1000)."
     ]
    }
   ],
   "source": [
    "from regressors import stats\n",
    "\n",
    "\n",
    "xlabels = np.array([\"X\"])\n",
    "print(\"\\n=========== SUMMARY ===========\")\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(xlabels.shape)\n",
    "stats.summary(model1, x, y, xlabels) # I don't know why it doesn't like my \"xlabels\" 😔?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-charlotte",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-radiation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "preceding-waterproof",
   "metadata": {},
   "source": [
    "### Bootstrap. Chapter 5, problem 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-universal",
   "metadata": {},
   "source": [
    "#### Number of Cases\n",
    " - The dataset contains a total of 506 cases.\n",
    "\n",
    "#### Variables\n",
    "  - There are 14 attributes in each case of the dataset. They are:\n",
    "  - CRIM - per capita crime rate by town\n",
    "  - ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "  - INDUS - proportion of non-retail business acres per town.\n",
    "  - CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "  - NOX - nitric oxides concentration (parts per 10 million)\n",
    "  - RM - average number of rooms per dwelling\n",
    "  - AGE - proportion of owner-occupied units built prior to 1940\n",
    "  - DIS - weighted distances to five Boston employment centres\n",
    "  - RAD - index of accessibility to radial highways\n",
    "  - TAX - full-value property-tax rate per $10,000 ----\n",
    "  -  / PTRATIO - pupil-teacher ratio by town\n",
    "  -   / B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "  -   / LSTAT - % lower status of the population\n",
    "  -   / MEDV - Median value of owner-occupied homes in $1000's\n",
    "  -------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "thirty-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  medv  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "boston_feat = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "boston_resp = pd.Series(boston.target).rename('medv')\n",
    "boston_df = pd.concat([boston_feat, boston_resp], axis=1)\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-playlist",
   "metadata": {},
   "source": [
    "#### (a) Based on this data set, provide an estimate for the population mean of medv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "imported-cartridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu_hat = boston_df['medv'].mean()\n",
    "display(mu_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-reasoning",
   "metadata": {},
   "source": [
    "#### (b) Provide an estimate of the standard error of μˆ Interpret this result.\n",
    "* SE   = std(medv) / sqrt(len(medv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "gross-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4084569346972866"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "medv = np.array(boston_df['medv'])\n",
    "SE   = np.std(medv) / np.sqrt(len(medv))\n",
    "display(SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-linux",
   "metadata": {},
   "source": [
    "* the standard errro is around 0.4. This ......."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-stopping",
   "metadata": {},
   "source": [
    "#### (c) Now estimate the standard error of μˆ using the bootstrap. How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "metallic-textbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE: 0.40517204469168827\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. take samples fron the data, with replacement\n",
    "2. calculate it's mean\n",
    "3. calculate the STD\n",
    "4. repeat 1,2,and 3\n",
    "'''\n",
    "\n",
    "# Compute standard error of the mean with the bootstrap approach\n",
    "\n",
    "def mean_boot(df, idx):\n",
    "    Z = np.array(df.loc[idx])\n",
    "    return np.mean(Z)\n",
    "\n",
    "def boot_idx(n):\n",
    "    return np.random.randint(low=0, high=n, size=n)\n",
    "\n",
    "def boot(fn, data_df, samples):\n",
    "    results = []\n",
    "    for s in range(samples):\n",
    "        Z = fn(data_df, boot_idx(data_df.shape[0]))\n",
    "        results += [Z]\n",
    "    return np.array(results)\n",
    "\n",
    "B = 10000\n",
    "mean_boot2  = boot(mean_boot, boston_df['medv'], samples=B)\n",
    "SE_pred    = np.std(mean_boot2) \n",
    "\n",
    "print('SE: ' + str(SE_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-means",
   "metadata": {},
   "source": [
    "* The SE from the bootstape is 0.41 which is very close to original SE 0.40 which proves that bootstrap is a great way to get estimates from a sample data when we don't have access to the population or have very small amount of data points\n",
    "* I tried the below version of code first and didn't work well because it gave me 0.9. I don't understand what I did wrong though?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "excellent-circle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92512288913418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# data sample\n",
    "data = medv\n",
    "# prepare bootstrap sample\n",
    "boot = resample(data, replace=True, n_samples=100, random_state=1)\n",
    "\n",
    "def SE(medv):\n",
    "     return np.std(medv) / np.sqrt(len(medv))\n",
    "     \n",
    "\n",
    "def bstrap(df):\n",
    "    tresult = 0\n",
    "    for i in range(0,1000):\n",
    "        X = resample(data, replace=True, n_samples=100, random_state=1)\n",
    "        result = SE(X)\n",
    "        tresult += result\n",
    "    fresult = tresult / 1000\n",
    "    print(fresult)\n",
    "    \n",
    "df3 = pd.DataFrame(medv, columns = ['medv'])    \n",
    "bstrap(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-carry",
   "metadata": {},
   "source": [
    "#### (d) Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results obtained using\n",
    "\n",
    "*  a 95% confidence interval =  [ μˆ − 2SE(μˆ), μˆ + 2SE(μˆ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "supreme-revolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 % confidence = ( 21.71274877614771 , 23.352863872073645 )\n"
     ]
    }
   ],
   "source": [
    "mu_hat   = np.mean(boston_df['medv'])\n",
    "low = mu_hat - (2*SE_pred)\n",
    "hi  = mu_hat + (2*SE_pred)\n",
    "print(\"95 % confidence = (\", low, \",\", hi,\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-luxembourg",
   "metadata": {},
   "source": [
    "* this means that the range of values of mean for different samples for the \"mdev\" lies in that range ( 21.71274877614771 , 23.352863872073645 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-timber",
   "metadata": {},
   "source": [
    "#### (e) Based on this dataset, provide an estimate, μˆmed, for the median value of medv in the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "compound-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 21.2\n"
     ]
    }
   ],
   "source": [
    "median_hat = np.median(boston_df['medv'])\n",
    "print('median: ' + str(median_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-tissue",
   "metadata": {},
   "source": [
    "#### (f)Estimate the standard error of μˆmed using bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "intended-upper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE: 0.37655998828207937\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. take n items from the given sample as a new sample\n",
    "2. calculate the sample median\n",
    "3. repeat 1 & 2 for B rounds, and we will get B new samples, with B sample medians\n",
    "4. estimate the standard error of medians\n",
    "   1.  calculate the mean of the previous sample of medians\n",
    "'''\n",
    "\n",
    "def median_boot(df, idx):\n",
    "    Z = np.array(df.loc[idx])\n",
    "    return np.median(Z)\n",
    "\n",
    "def boot_idx(n):\n",
    "    return np.random.randint(low=0, high=n, size=n)\n",
    "\n",
    "def boot(fn, data_df, samples):\n",
    "    results = []\n",
    "    for s in range(samples):\n",
    "        Z = fn(data_df, boot_idx(data_df.shape[0]))\n",
    "        results += [Z]\n",
    "    return np.array(results)\n",
    "\n",
    "B = 10000\n",
    "boot_obs   = boot(median_boot, boston_df['medv'], samples=B)\n",
    "SE_pred    = np.std(boot_obs) \n",
    "\n",
    "print('SE: ' + str(SE_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-conspiracy",
   "metadata": {},
   "source": [
    "#### g) Based on this data set, provide an estimate for the tenth percentile of medv in Boston suburbs. Call this quantity μˆ0.1. (You can use the quantile() function.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "material-congress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenth_percentile: 12.75\n"
     ]
    }
   ],
   "source": [
    "tenth_percentile = np.percentile(boston_df['medv'], 10)\n",
    "print('tenth_percentile: ' + str(tenth_percentile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-style",
   "metadata": {},
   "source": [
    "#### h) Use the bootstrap to estimate the standard error of μˆ0.1. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "intense-island",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE: 0.4973361870757043\n"
     ]
    }
   ],
   "source": [
    "def tenth_percentile(df, idx):\n",
    "    Z = np.array(df.loc[idx])\n",
    "    return np.percentile(Z, 10)\n",
    "\n",
    "def boot_idx(n):\n",
    "    return np.random.randint(low=0, high=n, size=n)\n",
    "\n",
    "def boot(fn, data_df, samples):\n",
    "    results = []\n",
    "    for s in range(samples):\n",
    "        Z = fn(data_df, boot_idx(data_df.shape[0]))\n",
    "        results += [Z]\n",
    "    return np.array(results)\n",
    "\n",
    "B = 10000\n",
    "boot_obs   = boot(tenth_percentile, boston_df['medv'], samples=B)\n",
    "SE_pred    = np.std(boot_obs) \n",
    "\n",
    "print('SE: ' + str(SE_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-watts",
   "metadata": {},
   "source": [
    "* The standard error for the tenth percentile is 0.49 which is very close to the one for the mean and median (mean=0.40 , median= 0.37)that were generated using bootstrape. \n",
    "* This is because the tenth percentile value is related to the mean and median values. If the mean increases, the the tenth percentile value will be shifted to a higher value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-delay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
